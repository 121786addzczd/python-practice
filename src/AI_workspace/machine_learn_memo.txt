■ 単回帰分析とは？
単回帰分析は、一つの説明変数を使用して目的変数を予測する分析手法です。

■ 回帰分析の基本
回帰分析は、統計学の手法の一つであり、この中でも「単回帰分析」を中心に解説を行います。

■ 回帰の意味
・ 一般的な定義：辞書によれば、「回帰」とは「一回りして元に戻ること」や「繰り返すこと」を意味します。
・ 統計学での定義：統計学における「回帰」は「予測」を意味する。このため、回帰分析は「予測分析」とも言える。

■ 単回帰分析の具体例
以下に具体例を示します。

・ 身長を元に体重を予測する。
・ レストランの座席数を基に売上を予測する。
・ 駅からの距離に基づいてマンションの価格を予測する。

「単」の部分は、予測に使用するデータの種類が一つであることを示しています。対照的に、予測に使用するデータの種類が2つ以上の場合は「重回帰分析」と呼ばれます。

例: マンションの価格を予測する際に、駅からの距離だけでなく、部屋の広さや階数、築年数などの複数の要因を考慮する場合がこれに当たります。

■ 重回帰分析とは
重回帰分析は、二種類以上の説明変数を使用して、量的データを予測する分析手法です。

■ 量的データと質的データ
・ 量的データ：身長や体重のように、データの大きさが比較できるもの。
・ 質的データ：男性・女性のように、データの大きさを比較できないもの。

■ 例
住宅価格の予測を例に挙げると、部屋の数のみを使用した予測は単回帰分析と言います。一方、部屋の数の他に、駅からの距離や築年数など、複数の説明変数を使用しての予測は重回帰分析となります。

■ 重回帰分析の概要
説明変数が2種類の場合を基本に解説します。

・ 築年数：ある地域の住宅の築年数の中央値。
・ 部屋数：その地域の住宅の平均の部屋数。
・ 住宅価格：その地域の物件の中央値。

ここで、築年数と部屋数が説明変数、住宅価格が目的変数となります。

■ 分析方法
基本的には最小二乗法を用いて、データに最も近い平面または曲面を求めることで、関係式を導き出します。この関係式を使用して、未知の目的変数を予測します。

もし説明変数が3種類以上存在する場合は、最小二乗法で「超平面」を求めることとなります。この超平面は、通常のグラフでの表現が難しいですが、2種類の説明変数を持つ場合の分析手法と基本は同じです。実際の業務で複数の説明変数を持つ場面は珍しくありません。

■ ロジスティック回帰分析
ロジスティック回帰分析は、手元のデータから目的のデータを分類する手法であり、大きさを予測できない質的データの予測に使用されます。

例として以下のケースで活用されることが多いです

・ 前日までの株価のデータから、翌日の株価が上がるか下がるかを予測する
・ 喫煙、飲酒、運動などの生活習慣から、その人が病気になるかならないかを予測する

■ ロジスティック回帰分析の手法の流れ
例として、130本のワインのデータがあると仮定します。ここで「color_intensity」はワインの色味の強さを示し、「class」はワインの種類を示しています。X軸をワインの色味の強さ、Y軸をワインの種類 (1 or 0) とすると、ロジスティック回帰分析を使うことで新たに得られたワインの色味の強さに基づいて、ワインの種類を予測することができます。

ロジスティック回帰分析では、予測される目的変数の確率を計算します。この確率は0から1の間の値を取ります。

■ ロジスティック回帰分析の手法
パラメータの最適値を求める際には「最尤推定法」が一般的に使用されます。

■ 最尤推定法
最尤推定法は、得られたデータに基づいて、最も確からしい条件やパラメータを推定する手法です。例えば、公平なコインを1000回投げた場合、表と裏が出る確率はおおよそ同じであると予測されますが、実際のデータに基づいてこの確率を求めるのが最尤推定法の目的です。

最尤推定法においては、交差エントロピー誤差を最小化するようにパラメータを更新していきます。具体的には

1. パラメータに適当な初期値を代入して、交差エントロピー誤差を計算する
2. 交差エントロピー誤差が最小となるように、パラメータを更新する
3. 最適なパラメータを用いて、関数式を定める

これにより、例えばワインの色味の強さから、そのワインがクラス1かクラス0かを予測する確率を計算できます。そして、この確率が0.5以上ならクラス1、0.5未満ならクラス0として分類します。

■ まとめ
1. ロジスティック回帰分析は目的変数を0または1で表現し、その確率を予測する
2. ロジスティック関数を使用して確率を計算する
3. 最尤推定法を用いて関数の最適なパラメータを求める
4. 得られた関数式を使用して確率を求め、それに基づいてデータを分類する